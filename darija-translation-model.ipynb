{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7918648e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchtext; torchtext.disable_torchtext_deprecation_warning()\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "import torch.optim as optim\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "import re\n",
    "import random\n",
    "import contractions\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4bfaef09",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = 'data/sentences.csv'\n",
    "\n",
    "unk_token = '<UNK>'\n",
    "start_token = '<SOS>'\n",
    "end_token = '<EOS'\n",
    "pad_token = '<PAD>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41ffbc75",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EnglishDarijaDataset(Dataset):\n",
    "    def __init__(self, path, tokenizer_en, tokenizer_da, max_len=20):\n",
    "        self.df = pd.read_csv(path)\n",
    "        self.df.dropna(inplace=True)\n",
    "        self.tokenizer_en = tokenizer_en\n",
    "        self.tokenizer_da = tokenizer_da\n",
    "        self.en_vocab = None\n",
    "        self.da_vocab = None\n",
    "        self.max_len = max_len\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    def __getitem__(self, idx):\n",
    "        en_s = self.df.iloc[idx]['eng']\n",
    "        da_s = self.df.iloc[idx]['darija']\n",
    "        en_l = tokenizer_en(en_s, self.max_len)\n",
    "        da_l = tokenizer_da(da_s, self.max_len)\n",
    "        if self.en_vocab and self.da_vocab:\n",
    "            en_ids = self.en_vocab.lookup_indices(en_l)\n",
    "            da_ids = self.da_vocab.lookup_indices(da_l)\n",
    "            return {\n",
    "                'en_sentence' : en_s,\n",
    "                'da_sentence' : da_s,\n",
    "                'en_tensors' : torch.tensor(en_ids),\n",
    "                'da_tensors' : torch.tensor(da_ids)\n",
    "            }\n",
    "        else:\n",
    "            return {\n",
    "                'en_sentence' : en_s,\n",
    "                'da_sentence' : da_s,\n",
    "                'en_tokens' : en_l,\n",
    "                'da_tokens' : da_l\n",
    "            }\n",
    "    def set_vocabs(self, en, da):\n",
    "        self.en_vocab = en\n",
    "        self.da_vocab = da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e4dd2b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer_en(s, max_len):\n",
    "    tokenizer = WordPunctTokenizer()\n",
    "    tokenized = tokenizer.tokenize(contractions.fix(s.lower()))\n",
    "    if len(tokenized) > max_len - 2:\n",
    "        tokenized = tokenized[:max_len-2]\n",
    "    tokenized.insert(0, start_token)\n",
    "    tokenized.append(end_token)\n",
    "    while len(tokenized) < max_len:\n",
    "        tokenized.append(pad_token)\n",
    "    return tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7a64f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer_da(s, max_len):\n",
    "    tokenizer = WordPunctTokenizer()\n",
    "    tokenized = tokenizer.tokenize(s)\n",
    "    if len(tokenized) > max_len - 2:\n",
    "        tokenized = tokenized[:max_len-2]\n",
    "    tokenized.insert(0, start_token)\n",
    "    tokenized.append(end_token)\n",
    "    while len(tokenized) < max_len:\n",
    "        tokenized.append(pad_token)\n",
    "    return tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "99885d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = EnglishDarijaDataset(DATA_PATH, tokenizer_en, tokenizer_da)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c2061e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, val_dataset, test_dataset = random_split(dataset, [0.8, 0.1, 0.1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f58dde4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_tokens = (data['en_tokens'] for data in train_dataset)\n",
    "da_tokens = (data['da_tokens'] for data in train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "612faabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "special_tokens = [start_token, end_token, pad_token, unk_token]\n",
    "\n",
    "en_vocab = build_vocab_from_iterator(en_tokens, min_freq=2, specials=special_tokens)\n",
    "\n",
    "da_vocab = build_vocab_from_iterator(da_tokens, min_freq=2, specials=special_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "57586dcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<SOS>', '<EOS', '<PAD>', '<UNK>', 'i', 'you', 'to', 'the', 'not', 'is']\n",
      "['<SOS>', '<EOS', '<PAD>', '<UNK>', '?', 'ghadi', 'had', 'ana', 't', 'chi']\n"
     ]
    }
   ],
   "source": [
    "print(en_vocab.get_itos()[:10])\n",
    "print(da_vocab.get_itos()[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b204c6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert en_vocab[unk_token] == da_vocab[unk_token]\n",
    "assert en_vocab[pad_token] == da_vocab[pad_token]\n",
    "\n",
    "unk_index = en_vocab[unk_token]\n",
    "pad_index = en_vocab[pad_token]\n",
    "\n",
    "en_vocab.set_default_index(unk_index)\n",
    "da_vocab.set_default_index(unk_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5e72af07",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.set_vocabs(en_vocab, da_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c653ddba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, embedding_dim, hidden_dim, n_layers, dropout):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_layers = n_layers\n",
    "        self.embedding = nn.Embedding(input_dim, embedding_dim)\n",
    "        self.rnn = nn.LSTM(embedding_dim, hidden_dim, n_layers, dropout=dropout)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    def forward(self, src):\n",
    "        embedded = self.dropout(self.embedding(src))\n",
    "        outputs, (hidden, cell) = self.rnn(embedded)\n",
    "        return hidden, cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "001a72fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_dim, embedding_dim, hidden_dim, n_layers, dropout):\n",
    "        super().__init__()\n",
    "        self.output_dim = output_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_layers = n_layers\n",
    "        self.embedding = nn.Embedding(output_dim, embedding_dim)\n",
    "        self.rnn = nn.LSTM(embedding_dim, hidden_dim, n_layers, dropout=dropout)\n",
    "        self.fc_out = nn.Linear(hidden_dim, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, input, hidden, cell):\n",
    "        input = input.unsqueeze(0)\n",
    "        embedded = self.dropout(self.embedding(input))\n",
    "        output, (hidden, cell) = self.rnn(embedded, (hidden, cell))\n",
    "        prediction = self.fc_out(output.squeeze(0))\n",
    "        return prediction, hidden, cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "28c0218b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self, src, trg, teacher_forcing_ratio):\n",
    "        batch_size = trg.shape[1]\n",
    "        trg_length = trg.shape[0]\n",
    "        trg_vocab_size = self.decoder.output_dim\n",
    "        outputs = torch.zeros(trg_length, batch_size, trg_vocab_size)\n",
    "        hidden, cell = self.encoder(src)\n",
    "        input = trg[0, :]\n",
    "        for t in range(1, trg_length):\n",
    "            output, hidden, cell = self.decoder(input, hidden, cell)\n",
    "            outputs[t] = output\n",
    "            teacher_force = random.random() < teacher_forcing_ratio\n",
    "            top1 = output.argmax(1)\n",
    "            input = trg[t] if teacher_force else top1\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c92fa9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.001\n",
    "batch_size = 32\n",
    "num_epochs = 1\n",
    "input_dim = len(en_vocab)\n",
    "output_dim = len(da_vocab)\n",
    "embedding_dim = 256\n",
    "hidden_dim = 512\n",
    "n_layers = 2\n",
    "dropout = 0.1\n",
    "\n",
    "encoder = Encoder(input_dim, embedding_dim, hidden_dim, n_layers, dropout)\n",
    "decoder = Decoder(output_dim, embedding_dim, hidden_dim, n_layers, dropout)\n",
    "\n",
    "model = Seq2Seq(encoder, decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c1fa1665",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "24d732f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6afd13bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss(ignore_index=pad_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0c421d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataloader, optimizer, loss_fn):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for batch in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        src = batch['en_tensors']\n",
    "        trg = batch['da_tensors']\n",
    "        pred = model(src, trg, 0.75)\n",
    "        loss = loss_fn(pred.view(-1, pred.shape[-1]), trg.view(-1))\n",
    "        train_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    return train_loss / len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "76d3845a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, dataloader, optimizer, loss_fn):\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            src = batch['en_tensors']\n",
    "            trg = batch['da_tensors']\n",
    "            pred = model(src, trg, 0)\n",
    "            loss = loss_fn(pred.view(-1, pred.shape[-1]), trg.view(-1))\n",
    "            val_loss += loss.item()\n",
    "    return val_loss / len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9e851973",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_losses(train_losses, val_losses):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(train_losses, label='Training Loss', color='blue')\n",
    "    plt.plot(val_losses, label='Validation Loss', color='red')\n",
    "    plt.title('Training and Validation Losses')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9c77ffdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_dataloader, val_dataloader, optimizer, loss_fn, num_epochs, plot=True):\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    for e in tqdm(range(1, num_epochs+1), desc=\"Training\", leave=True):\n",
    "        train_loss = train(model, train_dataloader, optimizer, loss_fn)\n",
    "        val_loss = validate(model, val_dataloader, optimizer, loss_fn)\n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss)\n",
    "        tqdm.write(f'Epoch {e}: Training Loss: {train_loss:.4f}, Validation Loss: {val_loss:.4f}')\n",
    "        tqdm.set_postfix({'train_loss': train_loss, 'val_loss': val_loss})\n",
    "    if plot:\n",
    "        plot_losses(train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3693cde7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|                                    | 0/1 [17:45<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Training Loss: 5.2710, Validation Loss: 4.7332\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'postfix'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[23], line 10\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, train_dataloader, val_dataloader, optimizer, loss_fn, num_epochs, plot)\u001b[0m\n\u001b[1;32m      8\u001b[0m     val_losses\u001b[38;5;241m.\u001b[39mappend(val_loss)\n\u001b[1;32m      9\u001b[0m     tqdm\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: Training Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Validation Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 10\u001b[0m     \u001b[43mtqdm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_postfix\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain_loss\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mval_loss\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loss\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m plot:\n\u001b[1;32m     12\u001b[0m     plot_losses(train_losses, val_losses)\n",
      "File \u001b[0;32m~/Personal/Coding/Machine Learning/darija-translator/darija-translator-venv/lib/python3.9/site-packages/tqdm/std.py:1428\u001b[0m, in \u001b[0;36mtqdm.set_postfix\u001b[0;34m(self, ordered_dict, refresh, **kwargs)\u001b[0m\n\u001b[1;32m   1425\u001b[0m         postfix[key] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(postfix[key])\n\u001b[1;32m   1426\u001b[0m     \u001b[38;5;66;03m# Else if it's a string, don't need to preprocess anything\u001b[39;00m\n\u001b[1;32m   1427\u001b[0m \u001b[38;5;66;03m# Stitch together to get the final postfix\u001b[39;00m\n\u001b[0;32m-> 1428\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpostfix\u001b[49m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(key \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m postfix[key]\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[1;32m   1429\u001b[0m                          \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m postfix\u001b[38;5;241m.\u001b[39mkeys())\n\u001b[1;32m   1430\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m refresh:\n\u001b[1;32m   1431\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrefresh()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'postfix'"
     ]
    }
   ],
   "source": [
    "train_model(model, train_dataloader, val_dataloader, optimizer, loss_fn, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "154c51b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, dataloader):\n",
    "    model.eval()\n",
    "    for batch in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        src = batch['en_tensors']\n",
    "        trg = batch['da_tensors']\n",
    "        pred = model(src, trg, 0)\n",
    "        print(src.size())\n",
    "        print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "70f2c3a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 20])\n",
      "tensor([[[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 1.5609e+01,  2.1714e+00, -8.0796e+00,  ..., -7.7806e-01,\n",
      "          -7.4093e+00, -3.0480e+00],\n",
      "         [-1.5111e-01, -9.5030e-01, -6.2552e+00,  ..., -3.0094e+00,\n",
      "          -3.8640e+00, -2.5819e+00],\n",
      "         [-5.1114e-01,  4.1533e+00, -8.4973e+00,  ..., -3.8553e+00,\n",
      "          -3.9768e+00, -5.4630e+00],\n",
      "         ...,\n",
      "         [-6.5557e-01,  6.4412e+00, -7.5200e+00,  ..., -3.2467e+00,\n",
      "          -4.7364e+00, -5.7155e+00],\n",
      "         [-6.5557e-01,  6.4412e+00, -7.5200e+00,  ..., -3.2467e+00,\n",
      "          -4.7364e+00, -5.7155e+00],\n",
      "         [-6.5557e-01,  6.4412e+00, -7.5200e+00,  ..., -3.2467e+00,\n",
      "          -4.7364e+00, -5.7155e+00]],\n",
      "\n",
      "        [[ 1.5779e+01,  1.7708e+00, -7.9394e+00,  ..., -8.0674e-01,\n",
      "          -7.3598e+00, -2.8204e+00],\n",
      "         [-1.3193e-02, -8.2389e-01, -6.5310e+00,  ..., -3.0913e+00,\n",
      "          -4.1955e+00, -2.7476e+00],\n",
      "         [-3.3169e-01,  3.2686e+00, -6.3954e+00,  ..., -3.0028e+00,\n",
      "          -3.0757e+00, -4.1767e+00],\n",
      "         ...,\n",
      "         [-6.0713e-01,  6.5775e+00, -7.6449e+00,  ..., -3.3159e+00,\n",
      "          -4.8579e+00, -5.8157e+00],\n",
      "         [-6.0713e-01,  6.5775e+00, -7.6449e+00,  ..., -3.3159e+00,\n",
      "          -4.8579e+00, -5.8157e+00],\n",
      "         [-6.0713e-01,  6.5775e+00, -7.6449e+00,  ..., -3.3159e+00,\n",
      "          -4.8579e+00, -5.8157e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 1.5929e+01,  1.2920e+00, -7.9102e+00,  ..., -9.3744e-01,\n",
      "          -7.2837e+00, -2.4683e+00],\n",
      "         [ 1.3328e-03, -9.2712e-01, -6.4965e+00,  ..., -3.0888e+00,\n",
      "          -3.8564e+00, -2.8324e+00],\n",
      "         [-2.9357e-01,  3.6468e+00, -7.2106e+00,  ..., -3.4252e+00,\n",
      "          -3.5822e+00, -4.7135e+00],\n",
      "         ...,\n",
      "         [-6.6492e-01,  6.5952e+00, -7.6319e+00,  ..., -3.3898e+00,\n",
      "          -4.8011e+00, -5.8535e+00],\n",
      "         [-6.6492e-01,  6.5952e+00, -7.6319e+00,  ..., -3.3898e+00,\n",
      "          -4.8011e+00, -5.8535e+00],\n",
      "         [-6.6492e-01,  6.5952e+00, -7.6319e+00,  ..., -3.3898e+00,\n",
      "          -4.8011e+00, -5.8535e+00]],\n",
      "\n",
      "        [[ 1.5907e+01,  1.3150e+00, -7.9512e+00,  ..., -9.7030e-01,\n",
      "          -7.2824e+00, -2.4890e+00],\n",
      "         [ 1.4211e-03, -9.2706e-01, -6.4958e+00,  ..., -3.0881e+00,\n",
      "          -3.8545e+00, -2.8325e+00],\n",
      "         [-2.9333e-01,  3.6469e+00, -7.2110e+00,  ..., -3.4255e+00,\n",
      "          -3.5824e+00, -4.7137e+00],\n",
      "         ...,\n",
      "         [-6.6468e-01,  6.5902e+00, -7.6280e+00,  ..., -3.3905e+00,\n",
      "          -4.7982e+00, -5.8500e+00],\n",
      "         [-6.6468e-01,  6.5902e+00, -7.6280e+00,  ..., -3.3905e+00,\n",
      "          -4.7982e+00, -5.8500e+00],\n",
      "         [-6.6468e-01,  6.5902e+00, -7.6280e+00,  ..., -3.3905e+00,\n",
      "          -4.7982e+00, -5.8500e+00]],\n",
      "\n",
      "        [[ 1.5859e+01,  1.3828e+00, -8.0514e+00,  ..., -1.0572e+00,\n",
      "          -7.3157e+00, -2.5576e+00],\n",
      "         [ 1.5141e-03, -9.2699e-01, -6.4953e+00,  ..., -3.0874e+00,\n",
      "          -3.8527e+00, -2.8325e+00],\n",
      "         [-2.9309e-01,  3.6470e+00, -7.2114e+00,  ..., -3.4258e+00,\n",
      "          -3.5826e+00, -4.7139e+00],\n",
      "         ...,\n",
      "         [-6.6364e-01,  6.5734e+00, -7.6157e+00,  ..., -3.3934e+00,\n",
      "          -4.7891e+00, -5.8386e+00],\n",
      "         [-6.6364e-01,  6.5734e+00, -7.6157e+00,  ..., -3.3934e+00,\n",
      "          -4.7891e+00, -5.8386e+00],\n",
      "         [-6.6364e-01,  6.5734e+00, -7.6157e+00,  ..., -3.3934e+00,\n",
      "          -4.7891e+00, -5.8386e+00]]], grad_fn=<CopySlices>)\n",
      "torch.Size([32, 20])\n",
      "tensor([[[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 1.5609e+01,  2.1714e+00, -8.0796e+00,  ..., -7.7806e-01,\n",
      "          -7.4093e+00, -3.0480e+00],\n",
      "         [-1.3127e-01, -9.8806e-01, -5.8921e+00,  ..., -2.8693e+00,\n",
      "          -3.6886e+00, -2.4169e+00],\n",
      "         [-5.7829e-01,  4.0915e+00, -8.3658e+00,  ..., -3.8368e+00,\n",
      "          -3.8501e+00, -5.4924e+00],\n",
      "         ...,\n",
      "         [-6.5557e-01,  6.4412e+00, -7.5200e+00,  ..., -3.2467e+00,\n",
      "          -4.7364e+00, -5.7155e+00],\n",
      "         [-6.5557e-01,  6.4412e+00, -7.5200e+00,  ..., -3.2467e+00,\n",
      "          -4.7364e+00, -5.7155e+00],\n",
      "         [-6.5557e-01,  6.4412e+00, -7.5200e+00,  ..., -3.2467e+00,\n",
      "          -4.7364e+00, -5.7155e+00]],\n",
      "\n",
      "        [[ 1.5779e+01,  1.7708e+00, -7.9394e+00,  ..., -8.0674e-01,\n",
      "          -7.3598e+00, -2.8204e+00],\n",
      "         [ 1.3038e-03, -7.1467e-01, -6.6982e+00,  ..., -3.1749e+00,\n",
      "          -4.2849e+00, -2.8544e+00],\n",
      "         [-3.3889e-01,  3.3316e+00, -6.6413e+00,  ..., -3.1304e+00,\n",
      "          -3.1893e+00, -4.3490e+00],\n",
      "         ...,\n",
      "         [-6.0713e-01,  6.5775e+00, -7.6449e+00,  ..., -3.3159e+00,\n",
      "          -4.8579e+00, -5.8157e+00],\n",
      "         [-6.0713e-01,  6.5775e+00, -7.6449e+00,  ..., -3.3159e+00,\n",
      "          -4.8579e+00, -5.8157e+00],\n",
      "         [-6.0713e-01,  6.5775e+00, -7.6449e+00,  ..., -3.3159e+00,\n",
      "          -4.8579e+00, -5.8157e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 1.5929e+01,  1.2920e+00, -7.9102e+00,  ..., -9.3744e-01,\n",
      "          -7.2837e+00, -2.4683e+00],\n",
      "         [-4.7314e-03, -9.2531e-01, -6.4942e+00,  ..., -3.0848e+00,\n",
      "          -3.8518e+00, -2.8341e+00],\n",
      "         [-3.0024e-01,  3.6483e+00, -7.2519e+00,  ..., -3.4363e+00,\n",
      "          -3.5922e+00, -4.7398e+00],\n",
      "         ...,\n",
      "         [-6.6492e-01,  6.5952e+00, -7.6319e+00,  ..., -3.3898e+00,\n",
      "          -4.8011e+00, -5.8535e+00],\n",
      "         [-6.6492e-01,  6.5952e+00, -7.6319e+00,  ..., -3.3898e+00,\n",
      "          -4.8011e+00, -5.8535e+00],\n",
      "         [-6.6492e-01,  6.5952e+00, -7.6319e+00,  ..., -3.3898e+00,\n",
      "          -4.8011e+00, -5.8535e+00]],\n",
      "\n",
      "        [[ 1.5907e+01,  1.3150e+00, -7.9512e+00,  ..., -9.7030e-01,\n",
      "          -7.2824e+00, -2.4890e+00],\n",
      "         [-4.5424e-03, -9.2543e-01, -6.4936e+00,  ..., -3.0842e+00,\n",
      "          -3.8501e+00, -2.8340e+00],\n",
      "         [-3.0008e-01,  3.6485e+00, -7.2512e+00,  ..., -3.4360e+00,\n",
      "          -3.5920e+00, -4.7395e+00],\n",
      "         ...,\n",
      "         [-6.6468e-01,  6.5902e+00, -7.6280e+00,  ..., -3.3905e+00,\n",
      "          -4.7982e+00, -5.8500e+00],\n",
      "         [-6.6468e-01,  6.5902e+00, -7.6280e+00,  ..., -3.3905e+00,\n",
      "          -4.7982e+00, -5.8500e+00],\n",
      "         [-6.6468e-01,  6.5902e+00, -7.6280e+00,  ..., -3.3905e+00,\n",
      "          -4.7982e+00, -5.8500e+00]],\n",
      "\n",
      "        [[ 1.5859e+01,  1.3828e+00, -8.0514e+00,  ..., -1.0572e+00,\n",
      "          -7.3157e+00, -2.5576e+00],\n",
      "         [-4.3471e-03, -9.2554e-01, -6.4931e+00,  ..., -3.0836e+00,\n",
      "          -3.8485e+00, -2.8340e+00],\n",
      "         [-2.9996e-01,  3.6487e+00, -7.2505e+00,  ..., -3.4357e+00,\n",
      "          -3.5918e+00, -4.7393e+00],\n",
      "         ...,\n",
      "         [-6.6364e-01,  6.5734e+00, -7.6157e+00,  ..., -3.3934e+00,\n",
      "          -4.7891e+00, -5.8386e+00],\n",
      "         [-6.6364e-01,  6.5734e+00, -7.6157e+00,  ..., -3.3934e+00,\n",
      "          -4.7891e+00, -5.8386e+00],\n",
      "         [-6.6364e-01,  6.5734e+00, -7.6157e+00,  ..., -3.3934e+00,\n",
      "          -4.7891e+00, -5.8386e+00]]], grad_fn=<CopySlices>)\n",
      "torch.Size([32, 20])\n",
      "tensor([[[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 1.5609e+01,  2.1714e+00, -8.0796e+00,  ..., -7.7806e-01,\n",
      "          -7.4093e+00, -3.0480e+00],\n",
      "         [-1.0614e-01, -9.7041e-01, -6.3828e+00,  ..., -3.0613e+00,\n",
      "          -3.9802e+00, -2.5918e+00],\n",
      "         [-5.8961e-01,  4.0798e+00, -8.4291e+00,  ..., -3.8766e+00,\n",
      "          -3.9268e+00, -5.4682e+00],\n",
      "         ...,\n",
      "         [-6.5557e-01,  6.4412e+00, -7.5200e+00,  ..., -3.2467e+00,\n",
      "          -4.7364e+00, -5.7155e+00],\n",
      "         [-6.5557e-01,  6.4412e+00, -7.5200e+00,  ..., -3.2467e+00,\n",
      "          -4.7364e+00, -5.7155e+00],\n",
      "         [-6.5557e-01,  6.4412e+00, -7.5200e+00,  ..., -3.2467e+00,\n",
      "          -4.7364e+00, -5.7155e+00]],\n",
      "\n",
      "        [[ 1.5779e+01,  1.7708e+00, -7.9394e+00,  ..., -8.0674e-01,\n",
      "          -7.3598e+00, -2.8204e+00],\n",
      "         [-1.9399e-02, -8.4233e-01, -6.5832e+00,  ..., -3.1121e+00,\n",
      "          -4.2241e+00, -2.7589e+00],\n",
      "         [-3.3263e-01,  3.2615e+00, -6.5677e+00,  ..., -3.0868e+00,\n",
      "          -3.0953e+00, -4.2851e+00],\n",
      "         ...,\n",
      "         [-6.0713e-01,  6.5775e+00, -7.6449e+00,  ..., -3.3159e+00,\n",
      "          -4.8579e+00, -5.8157e+00],\n",
      "         [-6.0713e-01,  6.5775e+00, -7.6449e+00,  ..., -3.3159e+00,\n",
      "          -4.8579e+00, -5.8157e+00],\n",
      "         [-6.0713e-01,  6.5775e+00, -7.6449e+00,  ..., -3.3159e+00,\n",
      "          -4.8579e+00, -5.8157e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 1.5929e+01,  1.2920e+00, -7.9102e+00,  ..., -9.3744e-01,\n",
      "          -7.2837e+00, -2.4683e+00],\n",
      "         [-3.8531e-03, -9.3357e-01, -6.5094e+00,  ..., -3.0911e+00,\n",
      "          -3.8559e+00, -2.8390e+00],\n",
      "         [-2.9002e-01,  3.6125e+00, -7.2356e+00,  ..., -3.4253e+00,\n",
      "          -3.5760e+00, -4.7251e+00],\n",
      "         ...,\n",
      "         [-6.6492e-01,  6.5952e+00, -7.6319e+00,  ..., -3.3898e+00,\n",
      "          -4.8011e+00, -5.8535e+00],\n",
      "         [-6.6492e-01,  6.5952e+00, -7.6319e+00,  ..., -3.3898e+00,\n",
      "          -4.8011e+00, -5.8535e+00],\n",
      "         [-6.6492e-01,  6.5952e+00, -7.6319e+00,  ..., -3.3898e+00,\n",
      "          -4.8011e+00, -5.8535e+00]],\n",
      "\n",
      "        [[ 1.5907e+01,  1.3150e+00, -7.9512e+00,  ..., -9.7030e-01,\n",
      "          -7.2824e+00, -2.4890e+00],\n",
      "         [-3.7200e-03, -9.3354e-01, -6.5082e+00,  ..., -3.0901e+00,\n",
      "          -3.8537e+00, -2.8388e+00],\n",
      "         [-2.8992e-01,  3.6131e+00, -7.2353e+00,  ..., -3.4253e+00,\n",
      "          -3.5762e+00, -4.7250e+00],\n",
      "         ...,\n",
      "         [-6.6468e-01,  6.5902e+00, -7.6280e+00,  ..., -3.3905e+00,\n",
      "          -4.7982e+00, -5.8500e+00],\n",
      "         [-6.6468e-01,  6.5902e+00, -7.6280e+00,  ..., -3.3905e+00,\n",
      "          -4.7982e+00, -5.8500e+00],\n",
      "         [-6.6468e-01,  6.5902e+00, -7.6280e+00,  ..., -3.3905e+00,\n",
      "          -4.7982e+00, -5.8500e+00]],\n",
      "\n",
      "        [[ 1.5859e+01,  1.3828e+00, -8.0514e+00,  ..., -1.0572e+00,\n",
      "          -7.3157e+00, -2.5576e+00],\n",
      "         [-3.5849e-03, -9.3351e-01, -6.5070e+00,  ..., -3.0893e+00,\n",
      "          -3.8516e+00, -2.8386e+00],\n",
      "         [-2.8984e-01,  3.6137e+00, -7.2350e+00,  ..., -3.4253e+00,\n",
      "          -3.5764e+00, -4.7250e+00],\n",
      "         ...,\n",
      "         [-6.6364e-01,  6.5734e+00, -7.6157e+00,  ..., -3.3934e+00,\n",
      "          -4.7891e+00, -5.8386e+00],\n",
      "         [-6.6364e-01,  6.5734e+00, -7.6157e+00,  ..., -3.3934e+00,\n",
      "          -4.7891e+00, -5.8386e+00],\n",
      "         [-6.6364e-01,  6.5734e+00, -7.6157e+00,  ..., -3.3934e+00,\n",
      "          -4.7891e+00, -5.8386e+00]]], grad_fn=<CopySlices>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 20])\n",
      "tensor([[[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 1.5609e+01,  2.1714e+00, -8.0796e+00,  ..., -7.7806e-01,\n",
      "          -7.4093e+00, -3.0480e+00],\n",
      "         [-1.1686e-01, -9.3598e-01, -6.0699e+00,  ..., -2.9160e+00,\n",
      "          -3.7778e+00, -2.5096e+00],\n",
      "         [-6.0429e-01,  4.4288e+00, -8.3960e+00,  ..., -3.7884e+00,\n",
      "          -4.0403e+00, -5.5840e+00],\n",
      "         ...,\n",
      "         [-6.5557e-01,  6.4412e+00, -7.5200e+00,  ..., -3.2467e+00,\n",
      "          -4.7364e+00, -5.7155e+00],\n",
      "         [-6.5557e-01,  6.4412e+00, -7.5200e+00,  ..., -3.2467e+00,\n",
      "          -4.7364e+00, -5.7155e+00],\n",
      "         [-6.5557e-01,  6.4412e+00, -7.5200e+00,  ..., -3.2467e+00,\n",
      "          -4.7364e+00, -5.7155e+00]],\n",
      "\n",
      "        [[ 1.5779e+01,  1.7708e+00, -7.9394e+00,  ..., -8.0674e-01,\n",
      "          -7.3598e+00, -2.8204e+00],\n",
      "         [ 1.7962e-03, -7.8012e-01, -6.6052e+00,  ..., -3.1291e+00,\n",
      "          -4.1808e+00, -2.8063e+00],\n",
      "         [-3.3138e-01,  3.3927e+00, -6.4123e+00,  ..., -2.9854e+00,\n",
      "          -3.1214e+00, -4.2251e+00],\n",
      "         ...,\n",
      "         [-6.0713e-01,  6.5775e+00, -7.6449e+00,  ..., -3.3159e+00,\n",
      "          -4.8579e+00, -5.8157e+00],\n",
      "         [-6.0713e-01,  6.5775e+00, -7.6449e+00,  ..., -3.3159e+00,\n",
      "          -4.8579e+00, -5.8157e+00],\n",
      "         [-6.0713e-01,  6.5775e+00, -7.6449e+00,  ..., -3.3159e+00,\n",
      "          -4.8579e+00, -5.8157e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 1.5929e+01,  1.2920e+00, -7.9102e+00,  ..., -9.3744e-01,\n",
      "          -7.2837e+00, -2.4683e+00],\n",
      "         [ 8.4983e-03, -9.1838e-01, -6.5164e+00,  ..., -3.0933e+00,\n",
      "          -3.8569e+00, -2.8447e+00],\n",
      "         [-3.0099e-01,  3.6725e+00, -7.1812e+00,  ..., -3.3936e+00,\n",
      "          -3.5845e+00, -4.7136e+00],\n",
      "         ...,\n",
      "         [-6.6492e-01,  6.5952e+00, -7.6319e+00,  ..., -3.3898e+00,\n",
      "          -4.8011e+00, -5.8535e+00],\n",
      "         [-6.6492e-01,  6.5952e+00, -7.6319e+00,  ..., -3.3898e+00,\n",
      "          -4.8011e+00, -5.8535e+00],\n",
      "         [-6.6492e-01,  6.5952e+00, -7.6319e+00,  ..., -3.3898e+00,\n",
      "          -4.8011e+00, -5.8535e+00]],\n",
      "\n",
      "        [[ 1.5907e+01,  1.3150e+00, -7.9512e+00,  ..., -9.7030e-01,\n",
      "          -7.2824e+00, -2.4890e+00],\n",
      "         [ 8.5682e-03, -9.1811e-01, -6.5152e+00,  ..., -3.0925e+00,\n",
      "          -3.8552e+00, -2.8444e+00],\n",
      "         [-3.0082e-01,  3.6726e+00, -7.1825e+00,  ..., -3.3946e+00,\n",
      "          -3.5849e+00, -4.7145e+00],\n",
      "         ...,\n",
      "         [-6.6468e-01,  6.5902e+00, -7.6280e+00,  ..., -3.3905e+00,\n",
      "          -4.7982e+00, -5.8500e+00],\n",
      "         [-6.6468e-01,  6.5902e+00, -7.6280e+00,  ..., -3.3905e+00,\n",
      "          -4.7982e+00, -5.8500e+00],\n",
      "         [-6.6468e-01,  6.5902e+00, -7.6280e+00,  ..., -3.3905e+00,\n",
      "          -4.7982e+00, -5.8500e+00]],\n",
      "\n",
      "        [[ 1.5859e+01,  1.3828e+00, -8.0514e+00,  ..., -1.0572e+00,\n",
      "          -7.3157e+00, -2.5576e+00],\n",
      "         [ 8.6291e-03, -9.1781e-01, -6.5141e+00,  ..., -3.0917e+00,\n",
      "          -3.8537e+00, -2.8441e+00],\n",
      "         [-3.0066e-01,  3.6727e+00, -7.1839e+00,  ..., -3.3956e+00,\n",
      "          -3.5852e+00, -4.7154e+00],\n",
      "         ...,\n",
      "         [-6.6364e-01,  6.5734e+00, -7.6157e+00,  ..., -3.3934e+00,\n",
      "          -4.7891e+00, -5.8386e+00],\n",
      "         [-6.6364e-01,  6.5734e+00, -7.6157e+00,  ..., -3.3934e+00,\n",
      "          -4.7891e+00, -5.8386e+00],\n",
      "         [-6.6364e-01,  6.5734e+00, -7.6157e+00,  ..., -3.3934e+00,\n",
      "          -4.7891e+00, -5.8386e+00]]], grad_fn=<CopySlices>)\n",
      "torch.Size([32, 20])\n",
      "tensor([[[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 1.5609e+01,  2.1714e+00, -8.0796e+00,  ..., -7.7806e-01,\n",
      "          -7.4093e+00, -3.0480e+00],\n",
      "         [-1.4674e-01, -9.3503e-01, -6.3613e+00,  ..., -3.0637e+00,\n",
      "          -3.9895e+00, -2.6166e+00],\n",
      "         [-5.8558e-01,  4.1482e+00, -8.3689e+00,  ..., -3.8394e+00,\n",
      "          -3.9015e+00, -5.4951e+00],\n",
      "         ...,\n",
      "         [-6.4834e-01,  6.4341e+00, -7.5202e+00,  ..., -3.2534e+00,\n",
      "          -4.7298e+00, -5.7114e+00],\n",
      "         [-6.4880e-01,  6.4397e+00, -7.5318e+00,  ..., -3.2542e+00,\n",
      "          -4.7339e+00, -5.7202e+00],\n",
      "         [-6.5493e-01,  6.4416e+00, -7.5372e+00,  ..., -3.2599e+00,\n",
      "          -4.7472e+00, -5.7233e+00]],\n",
      "\n",
      "        [[ 1.5779e+01,  1.7708e+00, -7.9394e+00,  ..., -8.0674e-01,\n",
      "          -7.3598e+00, -2.8204e+00],\n",
      "         [-3.9335e-03, -8.3239e-01, -6.6146e+00,  ..., -3.1335e+00,\n",
      "          -4.2654e+00, -2.7667e+00],\n",
      "         [-3.3491e-01,  3.3430e+00, -6.6222e+00,  ..., -3.1073e+00,\n",
      "          -3.1897e+00, -4.3388e+00],\n",
      "         ...,\n",
      "         [-6.0264e-01,  6.5607e+00, -7.6082e+00,  ..., -3.3111e+00,\n",
      "          -4.8202e+00, -5.7935e+00],\n",
      "         [-6.0508e-01,  6.5620e+00, -7.6125e+00,  ..., -3.3077e+00,\n",
      "          -4.8234e+00, -5.7961e+00],\n",
      "         [-6.0611e-01,  6.5646e+00, -7.6300e+00,  ..., -3.3117e+00,\n",
      "          -4.8469e+00, -5.8045e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 1.5929e+01,  1.2920e+00, -7.9102e+00,  ..., -9.3744e-01,\n",
      "          -7.2837e+00, -2.4683e+00],\n",
      "         [-1.7450e-03, -9.4619e-01, -6.5114e+00,  ..., -3.0989e+00,\n",
      "          -3.8665e+00, -2.8342e+00],\n",
      "         [-3.0281e-01,  3.6672e+00, -7.2591e+00,  ..., -3.4434e+00,\n",
      "          -3.6047e+00, -4.7478e+00],\n",
      "         ...,\n",
      "         [-6.5995e-01,  6.5611e+00, -7.6018e+00,  ..., -3.4022e+00,\n",
      "          -4.7765e+00, -5.8302e+00],\n",
      "         [-6.6277e-01,  6.5789e+00, -7.6172e+00,  ..., -3.3968e+00,\n",
      "          -4.7876e+00, -5.8434e+00],\n",
      "         [-6.6475e-01,  6.5932e+00, -7.6301e+00,  ..., -3.3896e+00,\n",
      "          -4.7996e+00, -5.8521e+00]],\n",
      "\n",
      "        [[ 1.5907e+01,  1.3150e+00, -7.9512e+00,  ..., -9.7030e-01,\n",
      "          -7.2824e+00, -2.4890e+00],\n",
      "         [-1.6816e-03, -9.4595e-01, -6.5100e+00,  ..., -3.0977e+00,\n",
      "          -3.8641e+00, -2.8340e+00],\n",
      "         [-3.0241e-01,  3.6669e+00, -7.2583e+00,  ..., -3.4433e+00,\n",
      "          -3.6043e+00, -4.7472e+00],\n",
      "         ...,\n",
      "         [-6.5685e-01,  6.5399e+00, -7.5899e+00,  ..., -3.4095e+00,\n",
      "          -4.7619e+00, -5.8159e+00],\n",
      "         [-6.6144e-01,  6.5619e+00, -7.6055e+00,  ..., -3.4015e+00,\n",
      "          -4.7783e+00, -5.8317e+00],\n",
      "         [-6.6437e-01,  6.5853e+00, -7.6240e+00,  ..., -3.3906e+00,\n",
      "          -4.7953e+00, -5.8467e+00]],\n",
      "\n",
      "        [[ 1.5859e+01,  1.3828e+00, -8.0514e+00,  ..., -1.0572e+00,\n",
      "          -7.3157e+00, -2.5576e+00],\n",
      "         [-1.6049e-03, -9.4572e-01, -6.5087e+00,  ..., -3.0966e+00,\n",
      "          -3.8618e+00, -2.8339e+00],\n",
      "         [-3.0202e-01,  3.6666e+00, -7.2575e+00,  ..., -3.4431e+00,\n",
      "          -3.6039e+00, -4.7466e+00],\n",
      "         ...,\n",
      "         [-6.5174e-01,  6.5070e+00, -7.5698e+00,  ..., -3.4166e+00,\n",
      "          -4.7369e+00, -5.7924e+00],\n",
      "         [-6.5857e-01,  6.5444e+00, -7.5964e+00,  ..., -3.4094e+00,\n",
      "          -4.7659e+00, -5.8198e+00],\n",
      "         [-6.6313e-01,  6.5681e+00, -7.6119e+00,  ..., -3.3948e+00,\n",
      "          -4.7859e+00, -5.8350e+00]]], grad_fn=<CopySlices>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_dataloader\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[31], line 7\u001b[0m, in \u001b[0;36mtest\u001b[0;34m(model, dataloader)\u001b[0m\n\u001b[1;32m      5\u001b[0m src \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124men_tensors\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      6\u001b[0m trg \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mda_tensors\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m----> 7\u001b[0m pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(src\u001b[38;5;241m.\u001b[39msize())\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(pred)\n",
      "File \u001b[0;32m~/Personal/Coding/Machine Learning/darija-translator/darija-translator-venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Personal/Coding/Machine Learning/darija-translator/darija-translator-venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[15], line 15\u001b[0m, in \u001b[0;36mSeq2Seq.forward\u001b[0;34m(self, src, trg, teacher_forcing_ratio)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m trg[\u001b[38;5;241m0\u001b[39m, :]\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, trg_length):\n\u001b[0;32m---> 15\u001b[0m     output, hidden, cell \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhidden\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcell\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m     outputs[t] \u001b[38;5;241m=\u001b[39m output\n\u001b[1;32m     17\u001b[0m     teacher_force \u001b[38;5;241m=\u001b[39m random\u001b[38;5;241m.\u001b[39mrandom() \u001b[38;5;241m<\u001b[39m teacher_forcing_ratio\n",
      "File \u001b[0;32m~/Personal/Coding/Machine Learning/darija-translator/darija-translator-venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Personal/Coding/Machine Learning/darija-translator/darija-translator-venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[14], line 16\u001b[0m, in \u001b[0;36mDecoder.forward\u001b[0;34m(self, input, hidden, cell)\u001b[0m\n\u001b[1;32m     14\u001b[0m embedded \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding(\u001b[38;5;28minput\u001b[39m))\n\u001b[1;32m     15\u001b[0m output, (hidden, cell) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrnn(embedded, (hidden, cell))\n\u001b[0;32m---> 16\u001b[0m prediction \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfc_out\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m prediction, hidden, cell\n",
      "File \u001b[0;32m~/Personal/Coding/Machine Learning/darija-translator/darija-translator-venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Personal/Coding/Machine Learning/darija-translator/darija-translator-venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Personal/Coding/Machine Learning/darija-translator/darija-translator-venv/lib/python3.9/site-packages/torch/nn/modules/linear.py:116\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "test(model, test_dataloader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "darija-translator-venv",
   "language": "python",
   "name": "darija-translator-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
